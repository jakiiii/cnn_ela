{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ada160-7e02-4358-aefe-800707bda7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 21:34:05.784469: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-06 21:34:05.784513: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-06 21:34:05.787194: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-06 21:34:05.997595: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-06 21:34:07.822208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, AvgPool2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from PIL import Image, ImageChops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e04bad-d84f-47d2-8268-f70caea52a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(dataset_path, path_original, path_tampered):\n",
    "    \"\"\"Preprocess images and return paths.\"\"\"\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "\n",
    "    total_original = [f for f in os.listdir(dataset_path + path_original) if os.path.splitext(f)[1].lower() in valid_extensions]\n",
    "    total_tampered = [f for f in os.listdir(dataset_path + path_tampered) if os.path.splitext(f)[1].lower() in valid_extensions]\n",
    "\n",
    "    pristine_images = [dataset_path + path_original + i for i in total_original]\n",
    "    fake_images = [dataset_path + path_tampered + i for i in total_tampered]\n",
    "\n",
    "    return pristine_images, fake_images\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess an image from its path.\"\"\"\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img)\n",
    "    return img_array\n",
    "\n",
    "\n",
    "def cnn_model():\n",
    "    \"\"\"Define the CNN model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu', input_shape=(224, 224, 3)))\n",
    "    model.add(AvgPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(AvgPool2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_metrics(history):\n",
    "    \"\"\"Plot training metrics.\"\"\"\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e5411-a89b-4658-a198-c5e9c4a92119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Paths and preprocessing\n",
    "    dataset_path = '/home/jaki/Dev/cnn_ela/CASIA2/'\n",
    "    path_original = 'Au/'\n",
    "    path_tampered = 'Tp/'\n",
    "    pristine_images, fake_images = preprocess_images(dataset_path, path_original, path_tampered)\n",
    "    # print(1, pristine_images)\n",
    "\n",
    "    # Labeling the images\n",
    "    pristine_labels = [0] * len(pristine_images)\n",
    "    fake_labels = [1] * len(fake_images)\n",
    "    # print(2, pristine_labels)\n",
    "    # print(3, fake_labels)\n",
    "\n",
    "    # Combining the images and labels\n",
    "    all_images = pristine_images + fake_images\n",
    "    all_labels = pristine_labels + fake_labels\n",
    "    # print(4, all_images)\n",
    "    # print(5, all_labels)\n",
    "\n",
    "    # Convert image paths to actual image data\n",
    "    x_train, x_dev, y_train, y_dev = train_test_split(all_images, all_labels, test_size=0.2, random_state=133,\n",
    "                                                      shuffle=True)\n",
    "    x_train = np.array([load_and_preprocess_image(img_path) for img_path in x_train])\n",
    "    x_dev = np.array([load_and_preprocess_image(img_path) for img_path in x_dev])\n",
    "    # print(6, x_train)\n",
    "    # print(7, x_dev)\n",
    "    # print(8, y_train)\n",
    "    # print(9, y_dev)\n",
    "    # print(10, x_train)\n",
    "    # print(11, x_dev)\n",
    "\n",
    "    # # Normalize the image data to [0, 1] range\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_dev = x_dev.astype('float32') / 255.0\n",
    "    # print(12, x_train)\n",
    "    # print(13, x_dev)\n",
    "\n",
    "    # # Convert labels to one-hot encoding\n",
    "    y_train = to_categorical(y_train, 2)\n",
    "    y_dev = to_categorical(y_dev, 2)\n",
    "    # print(14, y_train)\n",
    "    # print(15, y_dev)\n",
    "\n",
    "    # Model definition, compilation, and training\n",
    "    model = cnn_model()\n",
    "    optimizer = Adam(learning_rate=1e-4)\n",
    "    # print(16, optimizer)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=6, verbose=1, restore_best_weights=True)\n",
    "    # print(17, early_stop)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.22, patience=6, verbose=1, min_delta=0.0001,\n",
    "                                  min_lr=0.0001)\n",
    "    # print(18, reduce_lr)\n",
    "    history = model.fit(x_train, y_train, epochs=30, validation_data=(x_dev, y_dev), callbacks=[early_stop, reduce_lr],\n",
    "                        verbose=1, shuffle=True)\n",
    "    print(19, history)\n",
    "\n",
    "    # Plot metrics\n",
    "    plot_metrics(history)\n",
    "\n",
    "    # Evaluation\n",
    "    Y_pred = model.predict(x_dev)\n",
    "    Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "    Y_true = np.argmax(y_dev, axis=1)\n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "    # Assuming you have a function or method to plot the confusion matrix\n",
    "    # plot_confusion_matrix(confusion_mtx, classes=range(2))\n",
    "    print(classification_report(Y_true, Y_pred_classes))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
